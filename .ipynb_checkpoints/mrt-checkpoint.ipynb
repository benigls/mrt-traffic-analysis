{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MRT Line 3 Passenger Traffic (2012-2014) Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Dataset Link](http://data.gov.ph/dataset/metro-rail-transit-line-3-passenger-traffic-daily)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes\n",
    "\n",
    "- for this dataset the day starts at *03:00* and ends at *02:59*\n",
    "- for **2014** data it ends on **august 31**\n",
    "- for every station their are **entry** and **exit** value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions\n",
    "\n",
    "- [What station has the highest number of people to enter and drop-off?](http://localhost:8888/lab#What-station-has-the-highest-number-of-people-to-enter-and-drop-off?)\n",
    "- [What day usually people use MRT?](http://localhost:8888/lab#What-day-usually-people-use-mrt?)\n",
    "- For every hour what station has the highest number of people to enter and leave?\n",
    "- What direction usually people go? From north to south or vice versa?\n",
    "- What percentage of people in metro manila are using mrt?\n",
    "- Does holidays affect mrt traffic?\n",
    "- Does payday affect mrt traffic?\n",
    "\n",
    "\n",
    "## Graphs\n",
    "\n",
    "- Yearly line graph of daily traffic of mrt\n",
    "- Line graph of traffic of every station per year\n",
    "- \n",
    "\n",
    "\n",
    "## Model\n",
    "\n",
    "- Create model to predict the number of people to entry and exit in a station for a specific hour\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from itertools import groupby\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import datasets\n",
    "data_2012 = pd.read_csv('datasets/metro-rail-transit-line-3-passenger-traffic-daily-All-2017-10-28_2023/2012_mrt_hourly_daily_ridership 2.csv')\n",
    "data_2013 = pd.read_csv('datasets/metro-rail-transit-line-3-passenger-traffic-daily-All-2017-10-28_2023/2013_mrt_hourly_daily_ridership.csv')\n",
    "data_2014 = pd.read_csv('datasets/metro-rail-transit-line-3-passenger-traffic-daily-All-2017-10-28_2023/2014_mrt_hourly_daily_ridership.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add year for each data_*\n",
    "# so when i merge this later on i still have a reference for the year\n",
    "data_2012['year'] = 2012\n",
    "data_2013['year'] = 2013\n",
    "data_2014['year'] = 2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove unnecessary columns in data_2012 so the columns are the same with data_2013 and data_2014\n",
    "del data_2012['Unnamed: 29']\n",
    "del data_2012['Unnamed: 30']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if the columns of 3 datasets are the same\n",
    "data_2012.columns.tolist() == data_2013.columns.tolist() == data_2013.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for data_2013, some of the day column has only a value in the start of the day\n",
    "# in order to solve this\n",
    "\n",
    "current_day = 1\n",
    "\n",
    "def get_day(day):\n",
    "    # set global_current to use in this scope\n",
    "    global current_day\n",
    "    \n",
    "    # when day is null return the current_day (last day that occured)\n",
    "    if pd.isnull(day):\n",
    "        return current_day\n",
    "    \n",
    "    # when day is not null store it in current_day (last day that occured)\n",
    "    current_day = day\n",
    "    \n",
    "    return current_day\n",
    "\n",
    "data_2013['day'] = data_2013['day'].apply(lambda d: get_day(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{False}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if there still null in data_2013['day']\n",
    "set(data_2013['day'].isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# update data_2013 day columns to integer\n",
    "data_2013['day'] = data_2013['day'].apply(lambda d: int(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# merge datasets\n",
    "dataset = pd.concat([data_2012, data_2013, data_2014])\n",
    "dataset = dataset.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "entry_columns = [station for station in dataset.columns if 'entry' in station]\n",
    "exit_columns = [station for station in dataset.columns if 'exit' in station]\n",
    "stations = entry_columns + exit_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for every station column change \"-\" values to 0\n",
    "for station in stations:\n",
    "    dataset[station] = dataset[station].apply(lambda n: n if str(n).isdigit() else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change stations column type to numeric\n",
    "dataset[stations] = dataset[stations].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove range in time column add rename it to hour\n",
    "dataset['hour'] = dataset['time'].apply(lambda h: int(h[:2]))\n",
    "del dataset['time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trim month\n",
    "dataset['month'] = dataset['month'].apply(lambda m: m.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix day column cause for this dataset day starts at 03:00 and ends at 02:59\n",
    "first_row_string = ' '.join(str(v) for v in dataset[['year', 'month', 'day', 'hour']].loc[0].values)\n",
    "start_date = datetime.datetime.strptime(first_row_string, '%Y %B %d %H')\n",
    "current_date = start_date\n",
    "\n",
    "def get_true_datetime(date):\n",
    "    global current_date\n",
    "    \n",
    "    if date.hour == 0:\n",
    "        current_date = current_date + datetime.timedelta(days=1)\n",
    "\n",
    "    return [\n",
    "        current_date.year,\n",
    "        current_date.month,\n",
    "        current_date.day,\n",
    "        date.hour\n",
    "    ]\n",
    "\n",
    "dataset[['year', 'month', 'day', 'hour']] = dataset[['year', 'month', 'day', 'hour']].apply(lambda r: get_true_datetime(r), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add timestamp column\n",
    "dataset['timestamp'] = dataset[['year', 'month', 'day', 'hour']].apply(lambda r: datetime.datetime(r.year, r.month, r.day, r.hour), axis=1)\n",
    "\n",
    "del dataset['year']\n",
    "del dataset['month']\n",
    "del dataset['day']\n",
    "del dataset['hour']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.set_index('timestamp', drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset.ix['2012-02-01':'2012-02-01'][['shaw_blvd_entry', 'shaw_blvd_exit']].plot(figsize=(30, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What station has the highest number of people to enter and drop-off?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Taft Avenue Station** has the highest number of people to enter in the train followed by **North Avenue Station**. This make sense cause they are terminal stations.\n",
    "\n",
    "**Taft Avenue Station** has the highest number of people to exit in the train followed by **Cubao Station**. Same reason as the other one.\n",
    "\n",
    "**Cubao station** is connected to **LRT Line 2** and I think people use cubao to transfer to other line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "north_avenue_entry     3134.0\n",
       "quezon_avenue_entry    1500.5\n",
       "gma_kamuning_entry      827.0\n",
       "cubao_entry            2415.0\n",
       "santolan_entry          314.0\n",
       "ortigas_entry           723.0\n",
       "shaw_blvd_entry        2217.5\n",
       "boni_avenue_entry       947.0\n",
       "guadalupe_entry        1658.0\n",
       "buendia_entry           451.0\n",
       "ayala_avenue_entry     1261.0\n",
       "magallanes_entry       1363.0\n",
       "taft_entry             3671.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get median of every entry column\n",
    "dataset[entry_columns].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "north_avenue_exit     2122.0\n",
       "quezon_avenue_exit    1425.0\n",
       "gma_kamuning_exit      604.0\n",
       "cubao_exit            2757.0\n",
       "santolan_exit          332.0\n",
       "ortigas_exit          1171.5\n",
       "shaw_blvd_exit        2454.0\n",
       "boni_avenue_exit       950.0\n",
       "guadalupe_exit        1536.0\n",
       "buendia_exit           551.0\n",
       "ayala_avenue_exit     1793.0\n",
       "magallanes_exit        855.0\n",
       "taft_exit             3586.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get median of every exit column\n",
    "dataset[exit_columns].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What day usually people use MRT?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "People usually use the MRT in **Wednesday**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get entry and exit columns for every station\n",
    "# from: https://stackoverflow.com/questions/24310945/group-items-by-string-pattern-in-python\n",
    "keyf = lambda text: text.split('_')[0]\n",
    "group_stations = [list(items) for gr, items in groupby(sorted(stations), key=keyf)]\n",
    "group_stations = [{ 'name': keyf(stations[0]), 'stations': stations } for stations in group_stations]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create weekday column from timestamp\n",
    "dataset['weekday'] = dataset['timestamp'].apply(lambda x: x.strftime('%A'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group all entries by weekday and get the median\n",
    "weekday_df = dataset.groupby('weekday').agg('median')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the mean of the entry and exit columns for every station\n",
    "for group in group_stations:\n",
    "    weekday_df[group['name']] = weekday_df[group['stations']].mean(axis=1)\n",
    "    \n",
    "    for station in group['stations']:\n",
    "        del weekday_df[station]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "weekday\n",
       "Friday       1723.038462\n",
       "Monday       1773.461538\n",
       "Saturday     1555.000000\n",
       "Sunday       1062.500000\n",
       "Thursday     1795.057692\n",
       "Tuesday      1792.750000\n",
       "Wednesday    1885.153846\n",
       "dtype: float64"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weekday_df.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
